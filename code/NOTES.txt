So the vertexes stay the same, it's not changing the vertex buffer
it's only changing the Constants buffer,
and when used in the shader, it's adding an offset, which comes from the Constants buffer.

So to add a static square, I need to make a new shader that doesn't add an offset?
no.. I can just set a new constants buffer that has an offset of 0.

Ok, got that working. But that's just a workaround to reuse the same shader.
To actually draw a simple block background, it should have it's own basic shader.

Hm. The vertex shader is supposed to be responsible for getting the coordinates into clip space
so that's probably where I can do conversions
I can have all my world in my own coordinates, and have the shader convert it to [-1,1]




5/7 End of day notes:

I have many questions on how to set this all up.
My initial thoughts

I have some render struct thing
when i output some render struct thing, I throw it in a buffer for d3d to read
then in the vertex shader, i convert the vertices into clip space like it requires
then profit?

but like, what buffers need to be updating often vs init?
	The long post was kinda good for this, explaining 3 different constant buffers
	based on how often they are changing

	so really, just continue reading that post

I stopped reading right around "DirectX Demo Cont..." and "Load Demo Content"

5/9 sunday experimenting:

Q: Can I just set a Z value and have it Z-order my two shapes in front/behind automatically?
A: No, Setting Z does not automatically tell it the order, it still depends on the draw order.

Q: How do I have my own world coordinates? and have the Vertex buffer convert them?
First test, setting vertex data outside of [-1,1] range caused the square to take the entire screen
A: Basically a bunch of matrix math.
"Coords output by the vertex shader have the projection matrix applied, but not the perspective divide."
Basically this (in the vertex shader) (variables set up in a constants buffer):
	output.position = mul(input.position, worldMatrix);
	output.position = mul(output.position, viewMatrix);
	output.position = mul(output.position, projectionMatrix);

This questions is actually much more complicated than I thought
It's not only this matrix math between the Model View Projection (MVP)
but I think the vertex shader automatically goes from xyzw to xyz by dividing out the w,
thus finally converting it to normalized device coordinates.
The w is usually 1, but if it's considered with the projection (camera?) then it's possibly not 1
(this division is _perspective division_)
This article was ok. https://jsantell.com/model-view-projection/


5/10 finished reading the intro to dx11
My question from yesterday about the Z-ordering of rendering stuff..
Depth is handled by a DepthStencil buffer, which currently in our project is not set up
This sets up how things that are further away are not rendered in front of things that are closer.

Q: The IndexBuffer I was a little confused about, because our sample doesn't use one
It is optional, but what was it used for?
A: It's used to "render primitives more efficiently".
The numbers are the INDEXs into the vertex buffer.
So I believe if it says {0, 1, 2, ...}, it means that the first point on the primitive is those 3 vertexes (the first triangle)
Then you use DrawIndexed passing in the indexes! (instead of Draw)


I feel like I should have something like this:
Work in my own coordinates, obviously. That is basically a need
Then have a draw call that:
Updates a constant buffer with an offset calculated from my world pos
And I always use the offset to position things,
the vertex data will always be the same (square)
probably also need a scale too

5/11
started with what i mentioned yesterday, passing in some offset and getting that to render
but, needed some math:
ummm, so I started diving into some math
https://www.youtube.com/watch?v=bVYrd28ca_w&list=PLW3Zl3wyJwWMpFSRpeMmSBGDShbkiV1Cq&index=7

the scale thing I was trying to figure out is just a matrix multiply
so need to somehow figure that out with 2d????



was looking at this a little bit
https://www.enkisoftware.com/devlogpost-20200202-1-Runtime-Compiled-C++-Dear-ImGui-and-DirectX11-Tutorial
https://github.com/dougbinks/RCCpp_DX11_Example

good answer on history of opengl vs dx
https://softwareengineering.stackexchange.com/questions/60544/why-do-game-developers-prefer-windows/88055#88055



5/13
Alright, so back to the beginning.
I want to have 1 vertex buffer for a square, and to draw many of them with a simple offset

I also want to figure out how I can use my own world coordinates and have a conversion



ALLLLLLright..
Discovered ryan's app_template project, and man is it cleaaaaaan.
Moving my attention to that now.
One thing though: It sets up opengl, when I've just spent 2 weeks learning directx11
So the first task will be to set up d3d11, i think.
just going to try to mimic what he did with opengl and hope it works.

